{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL2K_1AZwutM"
      },
      "outputs": [],
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names\n",
        "!wget https://raw.githubusercontent.com/kimdinhloc/Applied_Parallel_Programming_HK2_2021_2022/main/Illustrated%20image/Dog.JPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoL3dzvDw0Ww"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import segmentation\n",
        "from numba import jit, prange, cuda\n",
        "import time\n",
        "import math\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXG3yftexCJp"
      },
      "outputs": [],
      "source": [
        "def load_model(Image):\n",
        "    ''' \n",
        "    Load YOLOv3 model and detect objects \n",
        "    return:\n",
        "    outs: list of detected objects\n",
        "    '''\n",
        "    try:\n",
        "        configuration = \"yolov3.cfg\"\n",
        "        weights = \"yolov3.weights\"\n",
        "        classesFile = \"coco.names\"\n",
        "        classes = None\n",
        "    \n",
        "        with open(classesFile, 'rt') as f:\n",
        "            classes = f.read().rstrip('\\n').split('\\n')\n",
        "\n",
        "        net = cv2.dnn.readNetFromDarknet(configuration, weights)\n",
        "        net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "        net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
        "    except:\n",
        "        print(\"Error: Cannot load model\")\n",
        "        sys.exit()\n",
        "    try:\n",
        "        inputWidth,inputHeight=608,608\n",
        "        blob = cv2.dnn.blobFromImage(Image, 1 / 255, (inputWidth, inputHeight), [0, 0, 0], 1, crop=False)\n",
        "        net.setInput(blob)\n",
        "        layersNames = net.getLayerNames()\n",
        "        outs = net.forward([layersNames[index[0] - 1] for index in net.getUnconnectedOutLayers()])\n",
        "    except:\n",
        "        print(\"Error: Cannot detect objects\")\n",
        "        sys.exit()\n",
        "    return outs\n",
        "\n",
        "def postprocess(frameHeight, frameWidth, outs,confThreshold=0.0):\n",
        "    boxes = []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            classId = np.argmax(scores)\n",
        "            confidence = scores[classId]\n",
        "            if confidence > confThreshold:\n",
        "                center_x = int(detection[0] * frameWidth)\n",
        "                center_y = int(detection[1] * frameHeight)\n",
        "                width = int(detection[2] * frameWidth)\n",
        "                height = int(detection[3] * frameHeight)\n",
        "                left = int(center_x - width / 2)\n",
        "                top = int(center_y - height / 2)\n",
        "                boxes.append([left, top, width, height])\n",
        "    return boxes\n",
        "#convert to CIE-LAB\n",
        "def BRG2CIELAB(inPixels):\n",
        "    '''\n",
        "    Convert BRG to CIELAB\n",
        "\n",
        "    praram:\n",
        "    ----\n",
        "    inPixels: numpy array of shape (B,G,R)\n",
        "\n",
        "    output:\n",
        "    ----\n",
        "    outPixels: numpy array of shape (L,a,b)\n",
        "    '''\n",
        "\n",
        "    #convert BGR to XYZ\n",
        "    #https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html#cvtcolor\n",
        "    #BRG -> CIE XYZ.Rec 709 with D65 white point\n",
        "    index = 0\n",
        "    for value in inPixels:\n",
        "        if value/255 > 0.04045:\n",
        "            inPixels[index] = (((value/255 + 0.055) / 1.055) ** 2.4)*100\n",
        "        else:\n",
        "            inPixels[index] = value/255 * 100/12.92\n",
        "        index += 1\n",
        "\n",
        "    XYZ_colvolution = np.matrix([[0.412453, 0.357580, 0.180423],\n",
        "              [0.212671, 0.715160, 0.072169],\n",
        "              [0.019334, 0.119193, 0.950227]], dtype=np.float32)\n",
        "    BGR = np.matrix([inPixels[2], inPixels[1], inPixels[0]]).T #.T is transpose to 3x1 matrix\n",
        "    XYZ = np.dot(XYZ_colvolution, BGR)\n",
        "    # Observer= 2°, Illuminant= D65\n",
        "    XYZ[0]=XYZ[0]/95.047\n",
        "    XYZ[1]=XYZ[1]/100.000\n",
        "    XYZ[2]=XYZ[2]/108.883\n",
        "\n",
        "    #convert XYZ to CIE-LAB\n",
        "    #https://en.wikipedia.org/wiki/Lab_color_space\n",
        "\n",
        "    index=0\n",
        "    for value in XYZ:\n",
        "        if value>0.008856:\n",
        "            XYZ[index]=np.power(value,1/3)\n",
        "        else:\n",
        "            XYZ[index]=(7.787*value)+(16/116)\n",
        "        index+=1\n",
        "\n",
        "    L=float(116*XYZ[1]-16)\n",
        "    a=float(500*(XYZ[0]-XYZ[1]))\n",
        "    b=float(200*(XYZ[1]-XYZ[2]))\n",
        "    return [round(L,4),round(a,4),round(b,4)]\n",
        "def convert2CIELAB(inImg):\n",
        "    '''\n",
        "    Convert RGB image to CIELAB\n",
        "    params:\n",
        "    inImg - image input\n",
        "    return:\n",
        "    outImg - image output\n",
        "    '''    \n",
        "    #initialize the output image\n",
        "    outImg=np.zeros(inImg.shape,dtype=np.float32)\n",
        "\n",
        "    #loop over the image, and convert the RGB values to CIELAB each pixel\n",
        "    for h in range(inImg.shape[0]):\n",
        "        for w in range(inImg.shape[1]):\n",
        "            outImg[h,w,:]=BRG2CIELAB(inImg[h,w,:])\n",
        "            \n",
        "    return outImg\n",
        "def find_local_minimum(inImg,center):\n",
        "    minGradient = 1\n",
        "    localMinium = center\n",
        "    for i in range(center[0] - 1, center[0] + 2):\n",
        "        for j in range(center[1] - 1, center[1] + 2):\n",
        "            cluster1 = inImg[j+1, i]\n",
        "            cluster2 = inImg[j, i+1]\n",
        "            cluster3 = inImg[j, i]\n",
        "            C=np.sqrt(pow(float(cluster1[0] - cluster3[0]),2)) +  np.sqrt(pow(float(cluster2[0] - cluster3[0]),2))\n",
        "            if C < minGradient:\n",
        "                minGradient = abs(cluster1[0] - cluster3[0]) + abs(cluster2[0] - cluster3[0])\n",
        "                localMinium = [i, j]\n",
        "    return localMinium\n",
        "def calculate_centers(inImg,S):\n",
        "    '''\n",
        "    Calculate the centers of the segments\n",
        "    params:\n",
        "    inImg - image input\n",
        "    S - number of segments\n",
        "    return:\n",
        "    centers - list of centers\n",
        "    '''\n",
        "    centers = []\n",
        "    for w in range(S, inImg.shape[1] - int(S/2), S):\n",
        "        for h in range(S, inImg.shape[0] - int(S/2), S):\n",
        "            nc = find_local_minimum(inImg,center=(w, h))\n",
        "            color = inImg[nc[1], nc[0]] #height x width\n",
        "            center = [color[0], color[1], color[2], nc[0], nc[1]] # l, a, b, height, width\n",
        "            centers.append(center)\n",
        "    return centers\n",
        "def generate_pixels(inImg,interations,distances,centers,clusters,S,m):\n",
        "    '''\n",
        "    Generate the segments\n",
        "    params:\n",
        "    --------\n",
        "    inImg - image input\n",
        "    interations - number of loops\n",
        "    distances - list of distances\n",
        "    centers - list of centers\n",
        "    clusters - list of clusters\n",
        "    S - number of segments\n",
        "    m - parameter for SLIC segmentation\n",
        "\n",
        "    return:\n",
        "    --------\n",
        "    centers - list of centers\n",
        "    distances - list of distances\n",
        "    clusters - list of clusters\n",
        "    '''\n",
        "\n",
        "    #init grid of pixels\n",
        "    indnp = np.mgrid[0:inImg.shape[0],0:inImg.shape[1]].swapaxes(0,2).swapaxes(0,1)\n",
        "    Img=inImg.copy()\n",
        "\n",
        "    #loop over the iterations\n",
        "    for i in range(interations):\n",
        "        distances = 1 * np.ones(Img.shape[:2])\n",
        "        for index in range(centers.shape[0]):\n",
        "            \n",
        "            #limit of the grid\n",
        "            x_low = int(max(centers[index][3]-S,0))\n",
        "            x_high = int(min(centers[index][3]+S,Img.shape[1]))\n",
        "            y_low = int(max(centers[index][4]-S,0))\n",
        "            y_high = int(min(centers[index][4]+S,Img.shape[0]))\n",
        "\n",
        "            #crop\n",
        "            cropimg = Img[y_low : y_high , x_low : x_high]\n",
        "            \n",
        "            # color difference\n",
        "            color_diff = cropimg - Img[int(centers[index][4]), int(centers[index][3])]\n",
        "\n",
        "            # color distance\n",
        "            color_distance = np.sqrt(np.sum(np.square(color_diff), axis=2))\n",
        "            ny, nx = np.ogrid[y_low : y_high, x_low : x_high]\n",
        "            pixdist = ((ny-centers[index][4])**2 + (nx-centers[index][3])**2)**0.5\n",
        "            dist = ((color_distance/m)**2 + (pixdist/S)**2)**0.5\n",
        "            distance_crop = distances[y_low : y_high, x_low : x_high]\n",
        "            idx = dist < distance_crop\n",
        "            distance_crop[idx] = dist[idx]\n",
        "            distances[y_low : y_high, x_low : x_high] = distance_crop\n",
        "            clusters[y_low : y_high, x_low : x_high][idx] = index\n",
        "\n",
        "        for k in range(len(centers)):\n",
        "            idx = (clusters == k)\n",
        "            colornp = inImg[idx]\n",
        "            distnp = indnp[idx]\n",
        "            centers[k][0:3] = np.sum(colornp, axis=0)\n",
        "            sumy, sumx = np.sum(distnp, axis=0)\n",
        "            centers[k][3:] = sumx, sumy\n",
        "            centers[k]= centers[k]/np.sum(idx)\n",
        "    return centers,distances,clusters\n",
        "def create_connectivity(inImg,centers,clusters):\n",
        "    '''\n",
        "    Create the connectivity matrix\n",
        "    params:\n",
        "    inImg - image input\n",
        "    centers - list of centers\n",
        "    clusters - list of clusters\n",
        "    return:\n",
        "    SLIC_new_clusters - list of clusters\n",
        "    '''\n",
        "    label = 0\n",
        "    adj_label = 0\n",
        "    lims=int(inImg.shape[0]*inImg.shape[1]/centers.shape[0])\n",
        "    \n",
        "    new_clusters = -1 * np.ones(inImg.shape[:2]).astype(np.int64)\n",
        "    elements = []\n",
        "    for i in range(inImg.shape[1]):\n",
        "        for j in range(inImg.shape[0]):\n",
        "            if new_clusters[j, i] == -1:\n",
        "                elements = []\n",
        "                elements.append((j, i))\n",
        "                for dx, dy in [(-1,0), (0,-1), (1,0), (0,1)]:\n",
        "                    x = elements[0][1] + dx\n",
        "                    y = elements[0][0] + dy\n",
        "                    if (x>=0 and x < inImg.shape[1] and \n",
        "                        y>=0 and y < inImg.shape[0] and \n",
        "                        new_clusters[y, x] >=0):\n",
        "                        adj_label = new_clusters[y, x]\n",
        "            count = 1\n",
        "            counter = 0\n",
        "            while counter < count:\n",
        "                for dx, dy in [(-1,0), (0,-1), (1,0), (0,1)]:\n",
        "                    x = elements[counter][1] + dx\n",
        "                    y = elements[counter][0] + dy\n",
        "\n",
        "                    if (x>=0 and x<inImg.shape[1] and y>=0 and y<inImg.shape[0]):\n",
        "                        if new_clusters[y, x] == -1 and clusters[j, i] == clusters[y, x]:\n",
        "                            elements.append((y, x))\n",
        "                            new_clusters[y, x] = label\n",
        "                            count+=1\n",
        "                counter+=1\n",
        "            if (count <= lims >> 2):\n",
        "                for counter in range(count):\n",
        "                    new_clusters[elements[counter]] = adj_label\n",
        "                label-=1\n",
        "            label+=1\n",
        "    SLIC_new_clusters = new_clusters\n",
        "    return SLIC_new_clusters\n",
        "def SLIC(srcImage,segmentSize,m=20,enforce_connectivity=False):\n",
        "    '''\n",
        "    SIMPLE LINEAR IMAGE SEGMENTATION\n",
        "\n",
        "    params:\n",
        "    ----------\n",
        "    srcImage - image to be segmented\n",
        "    segmentSize - size of segments\n",
        "    m = parameter for SLIC\n",
        "    enforce_connectivity - if True, enforce connectivity\n",
        "\n",
        "    return:\n",
        "    ----------\n",
        "    labels - segmented image\n",
        "    '''\n",
        "    # initialize SLIC\n",
        "    Image=srcImage.copy()\n",
        "    S=segmentSize\n",
        "    width=Image.shape[1]\n",
        "    height=Image.shape[0]\n",
        "    interations=10\n",
        "\n",
        "    # convert image to CieLAB\n",
        "    labImage=convert2CIELAB(Image)\n",
        "    \n",
        "    # initialize distance\n",
        "    distances = 1 * np.ones(labImage.shape[:2])\n",
        "\n",
        "    # initialize cluster\n",
        "    clusters = -1 * distances\n",
        "\n",
        "    # initialize cluster centers counter\n",
        "    center_counts = np.zeros(len(calculate_centers(labImage,S)))\n",
        "\n",
        "    # initialize cluster centers\n",
        "    centers = np.array(calculate_centers(labImage,S))\n",
        "\n",
        "    # generate superpixels\n",
        "    centers,distances,clusters=generate_pixels(labImage,interations,distances,centers,clusters,S,m)\n",
        "\n",
        "    if enforce_connectivity:\n",
        "        new_cluster=create_connectivity(labImage,centers,clusters)\n",
        "        centers=calculate_centers(labImage,S)\n",
        "    else:\n",
        "        new_cluster=clusters\n",
        "    return new_cluster\n",
        "def create_segmentation_mask(label,segmented,seg_mask,outline):\n",
        "    '''\n",
        "    Create segmentation mask\n",
        "    Parameters:\n",
        "    ----\n",
        "    label: label of segment\n",
        "    segmented: segmented image\n",
        "    seg_mask: segmentation mask\n",
        "    outline: outline of segment\n",
        "\n",
        "    return \n",
        "    seg_mask: segmentation mask\n",
        "    '''\n",
        "    for index in range(0, len(label)):\n",
        "        if label[index] == 0:\n",
        "            temp = outline == segmented[index]\n",
        "            seg_mask = seg_mask + temp\n",
        "    return seg_mask\n",
        "def meger_mask(srcImage,seg_mask):\n",
        "    '''\n",
        "    Merge mask with original image\n",
        "    Parameters:\n",
        "    ----\n",
        "    srcImage: Original image\n",
        "    seg_mask: Segmentation mask\n",
        "    '''\n",
        "    outImg=srcImage.copy()\n",
        "    height, width = srcImage.shape[:2]\n",
        "    for x in range(0, width):\n",
        "        for y in range(0, height):\n",
        "            if seg_mask[y, x] == 0:\n",
        "                outImg[y, x] = [0, 0, 0]\n",
        "    return outImg\n",
        "def remove_background(filename,segmentSize,m=20,enforce_connectivity=False,threshold=0.25,graussianKernel=5):\n",
        "    '''\n",
        "    Removing background - Xoá background\n",
        "    Parameters:\n",
        "    ----\n",
        "    filename: Đường dẫn chứa hình ảnh đầu vào\n",
        "    segmentSize: Kích thước của mỗi segment\n",
        "    m: Parameter for SLIC\n",
        "    enforce_connectivity: If True, enforce connectivity\n",
        "    threshold: Threshold for removing background\n",
        "  \n",
        "    '''\n",
        "\n",
        "    #Load image\n",
        "    srcImage = cv2.imread(filename)\n",
        "    Image=srcImage.copy()\n",
        "    Width, Height = Image.shape[1], Image.shape[0]\n",
        "\n",
        "    #load model\n",
        "    outs= load_model(Image)\n",
        "\n",
        "    #Box of Object\n",
        "    boxes = postprocess(Height, Width, outs)\n",
        "    if len(boxes):\n",
        "      [left, top, width, height] = boxes[0]\n",
        "    else:\n",
        "      [left, top, width, height] = [0, Height, Width, Height]\n",
        "\n",
        "    #Superpixels segmentation using SLIC\n",
        "    outline=SLIC(Image, segmentSize,m=20,enforce_connectivity=True)\n",
        "\n",
        "    #Grab Cut\n",
        "    mask = np.zeros(Image.shape[:2], np.uint8)\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "    rect = [left, top, left + width, top + height]\n",
        "    cv2.grabCut(Image, mask, rect, bgdModel, fgdModel, 1, cv2.GC_INIT_WITH_RECT)\n",
        "    cv2.grabCut(Image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_MASK)\n",
        "\n",
        "    grabMask = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
        "    segmented = np.unique(grabMask * outline)\n",
        "    segmented = segmented[1 : len(segmented)]\n",
        "    pxtotal = np.bincount(outline.flatten())\n",
        "    pxseg = np.bincount((grabMask * outline).flatten())\n",
        "    seg_mask = np.zeros(Image.shape[:2], np.uint8)\n",
        "    label = (pxseg[segmented] / pxtotal[segmented].astype(float)) < threshold\n",
        "    seg_mask=create_segmentation_mask(label,segmented,seg_mask,outline)\n",
        "    \n",
        "    #Graussian Blur\n",
        "    seg_mask = cv2.GaussianBlur(seg_mask, (graussianKernel, graussianKernel), 0)\n",
        "    \n",
        "    # Meger segmentation mask with original image\n",
        "    \n",
        "    outImg=meger_mask(Image,seg_mask)\n",
        "    return outImg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mQuWgETOa6rz"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "result=remove_background(\"/content/Dog.JPG\",5,20,False,0.25,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVXZyaAea7Wi"
      },
      "outputs": [],
      "source": [
        "plt.imshow(cv2.cvtColor(result,cv2.COLOR_RGB2BGR))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    '''\n",
        "    args:\n",
        "    ----\n",
        "    filename: file name of image\n",
        "    segmentSize: size of segment\n",
        "    m: Parameter for SLIC\n",
        "    enforce_connectivity: If True, enforce connectivity\n",
        "    threshold: Threshold for removing background\n",
        "\n",
        "    example:\n",
        "    ----\n",
        "    python remove_background.py filename segmentSize m enforce_connectivity threshold\n",
        "    > python remove_background.py test.jpg 200 20 True 0.25\n",
        "\n",
        "    OR USING RECOMMENDED PARAMETERS\n",
        "    python remove_background.py filename\n",
        "    > python remove_background.py test.jpg\n",
        "    '''\n",
        "    parser = sys.argv\n",
        "    if len(parser) != 7 and len(parser) != 2:\n",
        "        print(\"Wrong input\")\n",
        "        return\n",
        "    elif len(parser) == 7:\n",
        "        filename = parser[1]\n",
        "        segmentSize = int(parser[2])\n",
        "        m = int(parser[3])\n",
        "        enforce_connectivity = bool(parser[4])\n",
        "        threshold = float(parser[5])\n",
        "        graussianKernel = int(parser[6])\n",
        "        srcImage = cv2.imread(filename)\n",
        "        outImg = remove_background(srcImage,segmentSize,m,enforce_connectivity,threshold,graussianKernel)\n",
        "        cv2.imwrite(str(filename)+\"_output.jpg\", outImg)\n",
        "    elif len(parser) == 2:\n",
        "        filename = parser[1]\n",
        "        srcImage = cv2.imread(filename)\n",
        "        segmentSize=5\n",
        "        # if square image >10000000, segmentSize increase 2.5 each 1 milion more than 1 million\n",
        "        if srcImage.shape[0]*srcImage.shape[1]>10000000:\n",
        "            segmentSize=int(segmentSize+2.5*(srcImage.shape[0]*srcImage.shape[1]-1000000)//1000000)\n",
        "        m=20\n",
        "        enforce_connectivity=False\n",
        "        threshold=0.25\n",
        "        graussianKernel=segmentSize\n",
        "        outImg = remove_background(srcImage,segmentSize,m,enforce_connectivity,threshold,graussianKernel)\n",
        "        cv2.imwrite(str(filename.split()[0])+\"_output.jpg\", outImg)\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "KXK83OOz3Lsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python Seq.py Ball.JPG"
      ],
      "metadata": {
        "id": "YNqXnBi_5PuI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LTSS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}